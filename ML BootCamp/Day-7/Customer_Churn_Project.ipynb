{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo0Kglu_snAr"
      },
      "source": [
        "# **Welcome to the Final Project of Winter Bootcamp**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTkXmlEyT-SJ"
      },
      "source": [
        "## Project: Telco Customer Churn Prediction\n",
        "\n",
        "In the telecommunications industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate.\n",
        "\n",
        "- The Business Pain Point:\n",
        "Acquiring a new customer is estimated to be 5 to 25 times more expensive than retaining an existing one. Therefore, for a Telco company, Customer Retention is the most critical strategy to maximize profit.\n",
        "\n",
        "- The Goal:\n",
        "The management wants to reduce customer churn by identifying customers who are likely to leave before they actually leave. If we can predict who is at risk, the marketing team can offer them special discounts or better plans to keep them.\n",
        "\n",
        "2. Problem Statement\n",
        "\n",
        "- Objective: Develop a Machine Learning solution to predict whether a customer will Churn (leave the company) or Stay based on their account information, demographic details, and service usage.\n",
        "\n",
        "3. The Dataset\n",
        "\n",
        "We will use the Telco Customer Churn dataset.\n",
        "\n",
        "Source: [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD9xsuJO4TR7"
      },
      "source": [
        "**Importing the Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp9JH3D9T-SL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW9HM9JN4cDl"
      },
      "source": [
        "**Task: Reading and Exploring the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJtrKX0LT-SM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Telco-Customer-Churn.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Lf_ePNOfT-SN",
        "outputId": "252eb6fe-cc17-410c-e0cb-cf416c9ad3a5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upqwfR08T-SN"
      },
      "source": [
        "**TASK: Confirm quickly with .info() methods the datatypes and non-null values in your dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM0CWKa7T-SO",
        "outputId": "222cbdbc-5a00-47a2-94fb-4b85805eecab"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWZP2H9aT-SO"
      },
      "source": [
        "**TASK: Get a quick statistical summary of the numeric columns with .describe() , you should notice that many columns are categorical, meaning you will eventually need to convert them to dummy variables.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ygpkS5r_T-SO",
        "outputId": "0eab0bd6-25dc-4436-f522-4b41af8ab102"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hc5fggUT-SO"
      },
      "source": [
        "## General Feature Exploration\n",
        "\n",
        "**TASK: Confirm that there are no NaN cells by displaying NaN values per feature column.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "xgN8h0hDT-SO",
        "outputId": "99acd516-0234-40a1-8429-d77a4705060a"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zcsRM_3T-SP"
      },
      "source": [
        "**TASK:Display the balance of the class labels (Churn) with a Count Plot.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "fhuBMq9_T-SP",
        "outputId": "4504ce95-5705-42ad-8488-20529dfac396"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df,x='Churn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDwce7qOT-SP"
      },
      "source": [
        "**TASK: Explore the distrbution of TotalCharges between Churn categories with a Box Plot or Violin Plot.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "4IlWm6vtT-SP",
        "outputId": "799a7e30-921e-4b02-e4b0-d92ad63e4d94"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(data=df,x='Churn',y='TotalCharges')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULuZYAXCT-SP"
      },
      "source": [
        "The Violin Plot reveals that **Total Charges** is a strong indicator of churn risk, acting as a proxy for customer loyalty/tenure.\n",
        "\n",
        "| Inference | Churn = No (Stayed) | Churn = Yes (Left) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Density Peak** | The distribution peaks at **high Total Charges** (approx. \\$2,000 - \\$4,000). | The distribution is heavily concentrated at **very low Total Charges** (primarily under \\$1,000). |\n",
        "| **Correlation** | Customers with accumulated **high total charges** over their subscription lifetime are **less likely to churn**. | The majority of customers who churn are **low-value** or **new** customers. |\n",
        "| **Actionable Insight** | High total charges create a strong **retention barrier**. The highest churn risk is clustered within the **new or short-term** customer segment. | |\n",
        "\n",
        "***\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "There is a clear **negative correlation** between the accumulated amount a customer has paid and their likelihood of churning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXL0p-m1T-SP"
      },
      "source": [
        "**TASK: Create a boxplot showing the distribution of TotalCharges per Contract type, also add in a hue coloring based on the Churn class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "3a6gnckLT-SP",
        "outputId": "03312320-1d43-4ee5-d40e-8bdaa04beffe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.boxplot(data=df,y='TotalCharges',x='Contract',hue='Churn')\n",
        "plt.legend(loc=(1.1,0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSjJEtSXT-SP"
      },
      "source": [
        "This Box Plot shows that the length of the customer's contract is the **single most dominant predictor** of the total revenue accumulated over the customer's lifetime.\n",
        "\n",
        "| Inference | Month-to-month | One year | Two year |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Median Value** | **Lowest** (Median $\\approx \\$400$) | Mid-Range (Median $\\approx \\$1,600$) | **Highest** (Median $\\approx \\$3,000$) |\n",
        "| **Customer Value** | **Low-Value Segment.** Most customers here accumulate very few charges before ending their contract (high churn risk). | **Mid-Value Segment.** Shows a wider range of charges, indicating moderate loyalty. | **High-Value Segment.** Represents the company's most loyal and revenue-producing customer base. |\n",
        "| **Spread (IQR)** | **Most Concentrated.** The box (Interquartile Range) is very short, meaning most customers are clustered at the low end. | Wide IQR, indicating high variability in total charges. | **Widest Spread.** The largest IQR shows the highest overall range in customer value, reflecting longer tenure. |\n",
        "| **Outliers** | Shows many high outliers, meaning the few long-term customers who stay month-to-month are **exceptions** to the rule. | Very few high outliers, as most high-value customers are captured within the main box. | |\n",
        "\n",
        "***\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "Contract length acts as a strong measure of **customer loyalty and retention**. Shifting customers from 'Month-to-month' plans to 'One year' or 'Two year' plans is the most effective strategy to significantly increase customer lifetime value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2TVPxLBT-SQ"
      },
      "source": [
        "**TASK: Create a bar plot showing the correlation of the following features to the class label. Keep in mind, for the categorical features, you will need to convert them into dummy variables first, as you can only calculate correlation for numeric features.**\n",
        "\n",
        "    ['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'MultipleLines',\n",
        "     'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'InternetService',\n",
        "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "***Note, we specifically listed only the features above, you should not check the correlation for every feature, as some features have too many unique instances for such an analysis, such as customerID***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJlJbWn1T-SQ"
      },
      "outputs": [],
      "source": [
        "corr_df  = pd.get_dummies(df[['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'MultipleLines', 'InternetService',\n",
        "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
        "       'PaymentMethod','Churn']]).corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NKUrIYt9T-SQ",
        "outputId": "a6530db4-60a7-400c-e34d-8c0c103e2079"
      },
      "outputs": [],
      "source": [
        "corr_df['Churn_Yes'].sort_values().iloc[1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "2P-p4S3DT-SQ",
        "outputId": "1f79ec16-cbe1-4c0d-cdf7-c83b13f32c45"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.barplot(x=corr_df['Churn_Yes'].sort_values().iloc[1:-1].index,y=corr_df['Churn_Yes'].sort_values().iloc[1:-1].values)\n",
        "plt.title(\"Feature Correlation to Yes Churn\")\n",
        "plt.xticks(rotation=90);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI_VLhsqT-SQ"
      },
      "source": [
        "# Churn Analysis\n",
        "\n",
        "**This section focuses on segementing customers based on their tenure, creating \"cohorts\", allowing us to examine differences between customer cohort segments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B1QRNNET-SQ"
      },
      "source": [
        "**TASK: What are the 3 contract types available?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7dYk35BT-SR",
        "outputId": "f2d6ea9e-f6bc-46ba-b2c0-dbbe7aa59bd3"
      },
      "outputs": [],
      "source": [
        "df['Contract'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUn347dTT-SR"
      },
      "source": [
        "**TASK: Create a histogram displaying the distribution of 'tenure' column, which is the amount of months a customer was or has been on a customer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "vGnWlFJAT-SR",
        "outputId": "b83a0058-3580-42d2-c957-9c6ee50608b7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.histplot(data=df,x='tenure',hue='Churn',bins=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsugBz1ET-SR"
      },
      "source": [
        "**TASK: Now use the seaborn documentation as a guide to create histograms separated by two additional features, Churn and Contract.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "collapsed": true,
        "id": "mz8_ahJLT-SR",
        "outputId": "cb7da9c9-3804-4978-f577-db7d39760d6e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,3),dpi=200)\n",
        "sns.displot(data=df,x='tenure',bins=70,col='Contract',row='Churn');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Teyn8L7OT-SR"
      },
      "source": [
        "**TASK: Display a scatter plot of Total Charges versus Monthly Charges, and color hue by Churn.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "HEHd_1hXT-SR",
        "outputId": "7cde03c3-8b6d-45fc-ea81-444734800cb1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.scatterplot(data=df,x='MonthlyCharges',y='TotalCharges',hue='Churn', linewidth=0.5,alpha=0.5,palette='Dark2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsAjnt6nT-SR"
      },
      "source": [
        "### Creating Cohorts based on Tenure\n",
        "\n",
        "**Let's begin by treating each unique tenure length, 1 month, 2 month, 3 month...N months as its own cohort.**\n",
        "\n",
        "**TASK: Treating each unique tenure group as a cohort, calculate the Churn rate (percentage that had Yes Churn) per cohort. For example, the cohort that has had a tenure of 1 month should have a Churn rate of 61.99%. You should have cohorts 1-72 months with a general trend of the longer the tenure of the cohort, the less of a churn rate. This makes sense as you are less likely to stop service the longer you've had it.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rukKacFT-SR"
      },
      "outputs": [],
      "source": [
        "no_churn = df.groupby(['Churn','tenure']).count().transpose()['No']\n",
        "yes_churn = df.groupby(['Churn','tenure']).count().transpose()['Yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "n_KmnzJhT-SS",
        "outputId": "004a67d5-2754-44c4-bf96-3b3d9dc5787c"
      },
      "outputs": [],
      "source": [
        "no_churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVvmy9JIT-SS"
      },
      "outputs": [],
      "source": [
        "churn_rate = 100 * yes_churn / (no_churn+yes_churn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "c0z0DHe_T-SS",
        "outputId": "8093a62a-554e-4596-9f76-4f5d0448c8b1"
      },
      "outputs": [],
      "source": [
        "churn_rate.transpose()['customerID']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jea69uoGT-SS"
      },
      "source": [
        "**TASK: Now that you have Churn Rate per tenure group 1-72 months, create a plot showing churn rate per months of tenure.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "LDkU2EruT-SS",
        "outputId": "7631e509-4c29-48a6-ebf5-3cdd261b12b1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.lineplot(data=churn_rate.iloc[0])\n",
        "plt.ylabel('Churn Percentage');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhlgYx1rT-SS"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHcBZ8AlT-ST"
      },
      "source": [
        "### Broader Cohort Groups\n",
        "**TASK: Based on the tenure column values, create a new column called Tenure Cohort that creates 4 separate categories:**\n",
        "   * '0-12 Months'\n",
        "   * '24-48 Months'\n",
        "   * '12-24 Months'\n",
        "   * 'Over 48 Months'    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2TzTKlJT-ST"
      },
      "outputs": [],
      "source": [
        "def cohort(tenure):\n",
        "    if tenure < 13:\n",
        "        return '0-12 Months'\n",
        "    elif tenure < 25:\n",
        "        return '12-24 Months'\n",
        "    elif tenure < 49:\n",
        "        return '24-48 Months'\n",
        "    else:\n",
        "        return \"Over 48 Months\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UhKIUfET-ST"
      },
      "outputs": [],
      "source": [
        "df['Tenure Cohort'] = df['tenure'].apply(cohort)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Qa8tst69d8"
      },
      "source": [
        "**Task**\n",
        "- Create 'Family' column\n",
        "- Logic: Partner (1/0) + Dependents (1/0)\n",
        "- Result: 0 = Single, 1 = Has Partner OR Child, 2 = Has Both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voW06q8nT-ST"
      },
      "outputs": [],
      "source": [
        "df['Family'] = (df['Partner'] == 'Yes').astype(int) + (df['Dependents'] == 'Yes').astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lds8LWfp7SZM"
      },
      "source": [
        "**Task**\n",
        "- Create 'ServiceCount' column (How many products or services do they buy?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eeb2z6ewT-ST"
      },
      "outputs": [],
      "source": [
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "            'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
        "\n",
        "df['ServiceCount'] = df[services].apply(lambda x: (x == 'Yes').sum(), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iUEBR98T-ST"
      },
      "source": [
        "**TASK: Create a scatterplot of Total Charges versus Monthly Charts,colored by Tenure Cohort defined in the previous task.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "OFXR_EXAT-SU",
        "outputId": "3bdd9381-c061-445d-9b13-eb0d625e3a86"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.scatterplot(data=df,x='MonthlyCharges',y='TotalCharges',hue='Tenure Cohort',alpha=0.5,palette='Dark2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrGBDq32T-SU"
      },
      "source": [
        "**TASK: Create a count plot showing the churn count per cohort.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "pmSMQnyGT-SU",
        "outputId": "98a04dc7-68ea-4baf-c49c-b05f9d61f60c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4),dpi=200)\n",
        "sns.countplot(data=df,x='Tenure Cohort',hue='Churn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiRYPmyMT-SU",
        "outputId": "e043a4cb-c69a-46c3-a9e9-fe4c47d265f9"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgBrGnJQT-SU"
      },
      "outputs": [],
      "source": [
        "df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J12eJVZHT-SV"
      },
      "source": [
        "# Part 4: Predictive Modeling\n",
        "\n",
        "**Let's explore different classification based methods: A Single Decision Tree, Random Forest, AdaBoost, Gradient Boosting. Feel free to add any other supervised learning models to your comparisons!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5M07GGLT-SV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tncN1BSjT-SV"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['customerID','Churn'],axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM3x-07gT-SV"
      },
      "outputs": [],
      "source": [
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxA2q3eoT-SV"
      },
      "outputs": [],
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),\n",
        "        ('cat', OneHotEncoder(sparse_output=False), categorical_cols)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHpWoyKlT-SW",
        "outputId": "911b2662-6b98-4acc-cb80-4ea2c2cbff4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "model_params = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear'),\n",
        "        'params': {\n",
        "            # C: Inverse of regularization strength.\n",
        "            # Smaller values = stronger regularization (simpler model). Larger values = try to fit data perfectly.\n",
        "            'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "\n",
        "            # Penalty: How we punish complex models.\n",
        "            # 'l1' (Lasso) = can remove features (set coef to 0). 'l2' (Ridge) = just shrinks coefs.\n",
        "            'classifier__penalty': ['l1', 'l2']\n",
        "        }\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'model': GaussianNB(),\n",
        "        'params': {\n",
        "            # Var Smoothing: Adds a tiny value to variances to prevent division by zero errors.\n",
        "            # Helps when a feature has 0 variance in a specific class.\n",
        "            'classifier__var_smoothing': [1e-9, 1e-8, 1e-7]\n",
        "        }\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model': SVC(random_state=42, class_weight='balanced', probability=True),\n",
        "        'params': {\n",
        "            # C: Penalty for misclassifying a point.\n",
        "            # High C = Strict (risk of overfitting). Low C = Soft margin (allows some errors).\n",
        "            'classifier__C': [0.1, 1, 10],\n",
        "\n",
        "            # Kernel: The math used to project data into higher dimensions.\n",
        "            'classifier__kernel': ['rbf', 'poly'],\n",
        "\n",
        "            # Gamma: Defines how far the influence of a single training example reaches.\n",
        "            # High Gamma = Only close points matter (islands). Low Gamma = Far points matter.\n",
        "            'classifier__gamma': ['scale', 'auto', 0.1]\n",
        "        }\n",
        "    },\n",
        "    'KNN': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'params': {\n",
        "            # N Neighbors: The 'K' in KNN.\n",
        "            # Low K = sensitive to noise. High K = smoother decision boundary.\n",
        "            'classifier__n_neighbors': [3, 5, 9, 15],\n",
        "\n",
        "            # Weights: How much vote does each neighbor get?\n",
        "            # 'uniform' = all equal. 'distance' = closer neighbors have more influence.\n",
        "            'classifier__weights': ['uniform', 'distance'],\n",
        "\n",
        "            # P: The distance metric.\n",
        "            # 1 = Manhattan (City block distance). 2 = Euclidean (Straight line).\n",
        "            'classifier__p': [1, 2]\n",
        "        }\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "        'params': {\n",
        "            # Max Depth: How deep the tree can grow.\n",
        "            # None = unlimited (overfitting risk). Numbers restrict height.\n",
        "            'classifier__max_depth': [5, 10, 20, None],\n",
        "\n",
        "            # Min Samples Split: How many samples needed to justify splitting a node.\n",
        "            # Higher = prevents creating tiny, specific branches.\n",
        "            'classifier__min_samples_split': [2, 10, 20],\n",
        "\n",
        "            # Min Samples Leaf: Minimum samples required at a leaf node (end point).\n",
        "            # Crucial for smoothing the model.\n",
        "            'classifier__min_samples_leaf': [1, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "        'params': {\n",
        "            # N Estimators: Number of trees in the forest.\n",
        "            # More is usually better, but slower.\n",
        "            'classifier__n_estimators': [100, 200],\n",
        "\n",
        "            # Max Features: How many features to look at when splitting.\n",
        "            # 'sqrt' is standard. 'log2' looks at fewer features (more randomness).\n",
        "            'classifier__max_features': ['sqrt', 'log2'],\n",
        "\n",
        "            # (Same as Decision Tree above)\n",
        "            'classifier__max_depth': [10, 20, None],\n",
        "            'classifier__min_samples_leaf': [1, 4]\n",
        "        }\n",
        "    },\n",
        "    'AdaBoost': {\n",
        "        'model': AdaBoostClassifier(random_state=42),\n",
        "        'params': {\n",
        "            # Learning Rate: How much each tree contributes to the final answer.\n",
        "            # Low rate = need more trees, but usually better accuracy.\n",
        "            'classifier__learning_rate': [0.01, 0.1, 1.0],\n",
        "            'classifier__n_estimators': [50, 100, 200]\n",
        "        }\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'model': GradientBoostingClassifier(random_state=42),\n",
        "        'params': {\n",
        "            # Subsample: Fraction of samples used for fitting the individual base learners.\n",
        "            # < 1.0 results in Stochastic Gradient Boosting (reduces variance).\n",
        "            'classifier__subsample': [0.8, 1.0],\n",
        "\n",
        "            'classifier__n_estimators': [100, 200],\n",
        "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "            'classifier__max_depth': [3, 5, 8]\n",
        "        }\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(random_state=42, scale_pos_weight=3),\n",
        "        'params': {\n",
        "            # Gamma: Minimum loss reduction required to make a further partition.\n",
        "            # Acts as a regularization parameter (higher = more conservative).\n",
        "            'classifier__gamma': [0, 0.1, 0.2],\n",
        "\n",
        "            # Colsample Bytree: Subsample ratio of columns when constructing each tree.\n",
        "            # Similar to 'max_features' in Random Forest.\n",
        "            'classifier__colsample_bytree': [0.7, 1.0],\n",
        "\n",
        "            'classifier__n_estimators': [100, 200],\n",
        "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "            'classifier__max_depth': [3, 6, 10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "scores = []\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "    print(f\"  > Tuning {model_name}...\")\n",
        "\n",
        "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', mp['model'])])\n",
        "\n",
        "    clf = GridSearchCV(pipe, mp['params'], cv=3, scoring='recall', n_jobs=-1)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    scores.append({\n",
        "        'Model': model_name,\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'F1-Score': 0.0 if (recall_score(y_test, y_pred)+precision_score(y_test, y_pred))==0 else (2 * recall_score(y_test, y_pred) * precision_score(y_test, y_pred)) / (recall_score(y_test, y_pred) + precision_score(y_test, y_pred)),\n",
        "        'Best Params': str(clf.best_params_)\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qbncvCaT-SW"
      },
      "outputs": [],
      "source": [
        "final_df = pd.DataFrame(scores).sort_values(by='Recall', ascending=False)\n",
        "\n",
        "print(final_df[['Model', 'Recall', 'Precision', 'F1-Score']])\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "melted_df = final_df.melt(id_vars='Model', value_vars=['Recall', 'Precision'], var_name='Metric', value_name='Score')\n",
        "\n",
        "sns.barplot(x='Score', y='Model', hue='Metric', data=melted_df, palette='viridis')\n",
        "plt.title('The Ultimate Model Showdown: Precision vs. Recall')\n",
        "plt.axvline(0.80, color='red', linestyle='--', label='Target Recall (80%)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQhvS-OkUc6C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
