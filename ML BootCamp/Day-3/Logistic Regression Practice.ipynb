{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17d65a6",
   "metadata": {},
   "source": [
    "# Logistic Regression with Python\n",
    "\n",
    "For this Project we will be working with the [Titanic Data Set from Kaggle](https://www.kaggle.com/c/titanic). This is a very famous data set and very often is a student's first step in machine learning! \n",
    "\n",
    "We'll be trying to predict a classification- survival or deceased.\n",
    "Let's begin our understanding of implementing Logistic Regression in Python for classification.\n",
    "\n",
    "## Import Libraries\n",
    "Let's import some libraries to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8804bd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94dd3b9",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Let's start by reading in the titanic_train.csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11defa75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae6fc8f",
   "metadata": {},
   "source": [
    "**Quick exploration by looking at Top 5 rows of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac89da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55950037",
   "metadata": {},
   "source": [
    "\n",
    "**Titanic Dataset – Column Definitions**\n",
    "\n",
    "**1. PassengerId**\n",
    "\n",
    "A unique ID number assigned to each passenger (just for identification).\n",
    "\n",
    "**2. Survived**\n",
    "\n",
    "Whether the passenger survived the Titanic disaster.\n",
    "\n",
    "* `0` = Did **not** survive\n",
    "* `1` = **Survived**\n",
    "\n",
    "**3. Pclass**\n",
    "\n",
    "Passenger’s **ticket class** (a proxy for socio-economic status):\n",
    "\n",
    "* `1` = First class (richest)\n",
    "* `2` = Second class\n",
    "* `3` = Third class (lowest class)\n",
    "\n",
    "**4. Name**\n",
    "\n",
    "The full name of the passenger, including title (Mr., Mrs., Miss, etc.).\n",
    "\n",
    "**5. Sex**\n",
    "\n",
    "Passenger’s gender (`male` or `female`).\n",
    "\n",
    "**6. Age**\n",
    "\n",
    "Passenger’s age in years.\n",
    "(Some values are missing → unknown age.)\n",
    "\n",
    "**7. SibSp**\n",
    "\n",
    "Number of **siblings** or **spouses** the passenger had onboard.\n",
    "Examples:\n",
    "\n",
    "* 1 sister + 1 brother → **2**\n",
    "* Traveling with husband → **1**\n",
    "\n",
    "**8. Parch**\n",
    "\n",
    "Number of **parents** or **children** the passenger had onboard.\n",
    "Examples:\n",
    "\n",
    "* Traveling with mom → **1**\n",
    "* Traveling with both parents + 1 child → **3**\n",
    "\n",
    "**9. Ticket**\n",
    "\n",
    "Ticket number the passenger used to board the ship.\n",
    "\n",
    "**10. Fare**\n",
    "\n",
    "Amount of money the passenger paid for the ticket.\n",
    "\n",
    "**11. Cabin**\n",
    "\n",
    "Cabin number assigned to the passenger.\n",
    "Many values are missing (most passengers didn’t have cabins assigned).\n",
    "\n",
    "**12. Embarked**\n",
    "\n",
    "Port where the passenger boarded the Titanic:\n",
    "\n",
    "* `C` = Cherbourg\n",
    "* `Q` = Queenstown\n",
    "* `S` = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bb463",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Let's begin some exploratory data analysis! We'll start by checking out missing data!\n",
    "\n",
    "## Missing Data\n",
    "\n",
    "We can use seaborn to create a simple heatmap to see where we are missing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56a098",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98d733bf",
   "metadata": {},
   "source": [
    "Roughly 20 percent of the Age data is missing. The proportion of Age missing is likely small enough for reasonable replacement with some form of imputation. Looking at the Cabin column, it looks like we are just missing too much of that data to do something useful with at a basic level. We'll probably drop this later, or change it to another feature like \"Cabin Known: 1 or 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06e2b1",
   "metadata": {},
   "source": [
    "**Gender Distribution of The Passengers Based on Survival**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7443d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d27d4f",
   "metadata": {},
   "source": [
    "**Class Distribution of The Passengers Based on Survival**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33a265",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eee6cdf",
   "metadata": {},
   "source": [
    "**Age Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247f164",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0104d171",
   "metadata": {},
   "source": [
    "**Fare Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bd023",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40fd3c81",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "We want to fill in missing age data instead of just dropping the missing age data rows. One way to do this is by filling in the mean age of all the passengers (imputation).\n",
    "However we can be smarter about this and check the average age by passenger class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40908d",
   "metadata": {},
   "source": [
    "**For this you can plot the boxplot with X as Pclass and y as Age for different Sex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903d3f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe572756",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32ca56c",
   "metadata": {},
   "source": [
    "## Imputation for the Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9d0fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a753bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "834668bb",
   "metadata": {},
   "source": [
    "Great! Let's go ahead and drop the Cabin column that is NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f8329",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a413c8a7",
   "metadata": {},
   "source": [
    "## Converting Categorical Features \n",
    "\n",
    "We'll need to convert categorical features to dummy variables using pandas! Otherwise our machine learning algorithm won't be able to directly take in those features as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4a054",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bac12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffd6f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f662f4",
   "metadata": {},
   "source": [
    "Great! Our data is ready for our model!\n",
    "\n",
    "# Building a Logistic Regression model\n",
    "\n",
    "Let's start by splitting our data into a training set and test set (there is another test.csv file that you can play around with in case you want to use all this data for training).\n",
    "\n",
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760b2c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40f2736e",
   "metadata": {},
   "source": [
    "## Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2ee5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "817f79ab",
   "metadata": {},
   "source": [
    "Let's move on to evaluate our model!\n",
    "## Evaluation\n",
    "We can check precision,recall,f1-score using classification report!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bb8de",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Classification Evaluation Metrics**\n",
    "\n",
    "In classification problems, we compare the model’s predictions with the true labels using metrics such as **Precision**, **Recall**, and **F1-score**.\n",
    "\n",
    "These metrics come from the **confusion matrix**:\n",
    "\n",
    "|                     | Predicted Positive      | Predicted Negative      |\n",
    "| ------------------- | ----------------------- | ----------------------- |\n",
    "| **Actual Positive** | **True Positive (TP)**  | **False Negative (FN)** |\n",
    "| **Actual Negative** | **False Positive (FP)** | **True Negative (TN)**  |\n",
    "\n",
    "---\n",
    "\n",
    "# **Definitions of TP, FP, FN, TN**\n",
    "\n",
    "### **True Positive (TP)**\n",
    "\n",
    "Cases where the model **correctly predicted Positive**.\n",
    "Example: model says “disease” and the person actually has the disease.\n",
    "\n",
    "### **False Positive (FP)**\n",
    "\n",
    "Cases where the model **predicted Positive**, but the actual class was Negative.\n",
    "Example: model says “spam”, but the email is actually normal.\n",
    "(Also called **Type I Error**.)\n",
    "\n",
    "### **False Negative (FN)**\n",
    "\n",
    "Cases where the model **predicted Negative**, but the actual class was Positive.\n",
    "Example: model says “no disease”, but the person is actually sick.\n",
    "(Also called **Type II Error**.)\n",
    "\n",
    "### **True Negative (TN)**\n",
    "\n",
    "Cases where the model **correctly predicted Negative**.\n",
    "Example: model says “not spam”, and the email is indeed not spam.\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Precision**\n",
    "\n",
    "**Precision** tells us:\n",
    "\n",
    "> “Out of all the predictions the model said were *positive*, how many were actually positive?”\n",
    "\n",
    "It measures the **accuracy of positive predictions**.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "\n",
    "* High precision = very few **false positives**\n",
    "* Useful when **false positives are costly**\n",
    "  (e.g., spam detection → don’t mark real emails as spam)\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Recall (Sensitivity / True Positive Rate)**\n",
    "\n",
    "**Recall** tells us:\n",
    "\n",
    "> “Out of all the actual positive cases, how many did the model correctly identify?”\n",
    "\n",
    "It measures the model’s ability to **find all positive cases**.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "\n",
    "* High recall = very few **false negatives**\n",
    "* Useful when **missing a positive is costly**\n",
    "  (e.g., disease detection → do not miss sick patients)\n",
    "\n",
    "---\n",
    "\n",
    "# **3. F1-Score**\n",
    "\n",
    "**F1-score** is the **harmonic mean** of Precision and Recall.\n",
    "\n",
    "It balances both metrics, giving a single score that considers both **false positives** and **false negatives**.\n",
    "\n",
    "$$\n",
    "\\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "* High F1-score = good balance between precision and recall\n",
    "* Most useful when:\n",
    "\n",
    "  * Classes are **imbalanced**\n",
    "  * You care about both catching positives **and** not raising false alarms\n",
    "\n",
    "---\n",
    "\n",
    "# **4. Support**\n",
    "\n",
    "**Support** is simply:\n",
    "\n",
    "> “How many actual samples of this class exist in the dataset?”\n",
    "\n",
    "It does *not* measure performance; it only tells you the number of true samples.\n",
    "\n",
    "$$\n",
    "\\text{Support} = \\text{Number of actual instances of each class}\n",
    "$$\n",
    "\n",
    "\n",
    "Support helps you evaluate:\n",
    "\n",
    "* class imbalance\n",
    "* how reliable the metrics are (small support → unstable or misleading values)\n",
    "\n",
    "---\n",
    "\n",
    "# **Summary of Interpretation**\n",
    "\n",
    "| Metric        | Measures                        | Good When                   | Bad When                                 |\n",
    "| ------------- | ------------------------------- | --------------------------- | ---------------------------------------- |\n",
    "| **Precision** | Quality of positive predictions | False positives must be low | Model misses many positives              |\n",
    "| **Recall**    | Ability to find all positives   | False negatives must be low | Too many false positives                 |\n",
    "| **F1-Score**  | Balance of Prec. & Recall       | Need one combined score     | Classes balanced & accuracy is preferred |\n",
    "| **Support**   | Count of true samples           | Check class imbalance       | Not a measure of accuracy                |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
