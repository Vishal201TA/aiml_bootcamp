{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27f18c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ‚≠ê **Module 1 ‚Äî LLM Foundations**\n",
    "\n",
    "---\n",
    "\n",
    "# **1.1 LLM Basics**\n",
    "\n",
    "## **üîπ What Are Tokens?**\n",
    "\n",
    "**Token = a small unit of text (word or sub-word) that the model reads.**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* ‚ÄúApple‚Äù ‚Üí 1 token\n",
    "* ‚ÄúIntelligence‚Äù ‚Üí 1 token\n",
    "* ‚ÄúI love India‚Äù ‚Üí 4 tokens\n",
    "* ‚Äú‡§®‡§Æ‡§∏‡•ç‡§§‡•á‚Äù ‚Üí usually 1 token\n",
    "\n",
    "Why tokens matter:\n",
    "\n",
    "* Token count affects **cost**\n",
    "* Token count affects **speed**\n",
    "* Token limit defines how much context the model can \"see\"\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ What Is a Context Window?**\n",
    "\n",
    "**Context window = the maximum number of tokens the model can process at one time.**\n",
    "\n",
    "Think of it like the model‚Äôs ‚Äúworking memory.‚Äù\n",
    "\n",
    "Examples:\n",
    "\n",
    "* GPT-4o: ~200K tokens\n",
    "* Llama 3: 8K‚Äì128K tokens\n",
    "* Gemini 1.5: 1M tokens (largest currently)\n",
    "\n",
    "Why context windows matter:\n",
    "\n",
    "* Determines how long a prompt can be\n",
    "* Determines how many pages of a PDF the model can read\n",
    "* Limits how much an agent can remember in one task\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ What Are Embeddings?**\n",
    "\n",
    "**Embedding = a numerical vector representation of text, images, or audio.**\n",
    "\n",
    "More simply:\n",
    "\n",
    "> **Embedding = how AI ‚Äúunderstands‚Äù meaning.**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Embedding(\"dog\")  ‚Üí similar numbers ‚Üí Embedding(\"pet\")\n",
    "Embedding(\"investment\")  ‚Üí similar numbers ‚Üí Embedding(\"finance\")\n",
    "```\n",
    "\n",
    "Embeddings turn text into **numbers** so that computers can compute:\n",
    "\n",
    "* Similarity\n",
    "* Context\n",
    "* Meaning\n",
    "\n",
    "### Why embeddings are important in agent systems:\n",
    "\n",
    "Agents need embeddings for tasks like:\n",
    "\n",
    "* RAG (Retrieval Augmented Generation)\n",
    "* Semantic search\n",
    "* Long-term memory\n",
    "* Categorization\n",
    "* Document similarity\n",
    "* Multimodal memory (images + text)\n",
    "\n",
    "### Key idea:\n",
    "\n",
    "**LLMs generate text, but embeddings allow LLMs to *understand relationships between texts*.**\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Model Selection**\n",
    "\n",
    "### **What is a model?**\n",
    "\n",
    "**A model = a neural network trained to understand and generate language.**\n",
    "\n",
    "We choose models based on:\n",
    "\n",
    "* Speed\n",
    "* Cost\n",
    "* Reasoning power\n",
    "* Context window\n",
    "* Multimodal abilities (images, audio, video)\n",
    "\n",
    "### Model types:\n",
    "\n",
    "#### GPT-4o\n",
    "\n",
    "* Strong reasoning\n",
    "* Strong tool calling\n",
    "* Good for agents\n",
    "\n",
    "#### Claude 3.5\n",
    "\n",
    "* Excellent reasoning & analysis\n",
    "* Very safe\n",
    "* Good for long documents\n",
    "\n",
    "#### Gemini 1.5\n",
    "\n",
    "* Best multimodal model\n",
    "* Best for document-heavy agents\n",
    "* Massive context window\n",
    "\n",
    "#### Llama 3\n",
    "\n",
    "* Open source\n",
    "* Good for self-hosting\n",
    "* Doesn‚Äôt require cloud\n",
    "\n",
    "---\n",
    "\n",
    "# **1.2 Prompt Engineering**\n",
    "\n",
    "## **üîπ What Is a Prompt?**\n",
    "\n",
    "**Prompt = the input instructions given to an LLM.**\n",
    "\n",
    "Types:\n",
    "\n",
    "* System prompt\n",
    "* User prompt\n",
    "* Tool instructions\n",
    "* Output instructions\n",
    "\n",
    "For agents, we write prompts that instruct the model to:\n",
    "\n",
    "* Choose tools\n",
    "* Output JSON\n",
    "* Follow rules\n",
    "* Maintain structure\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ System Prompts for Agents**\n",
    "\n",
    "Definition:\n",
    "\n",
    "**System prompt = the ‚Äúrole + rules‚Äù that control agent behavior.**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "You are an AI agent.\n",
    "Use tools when necessary.\n",
    "Always respond in valid JSON.\n",
    "Never hallucinate tool names.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Tool Calling-Friendly Prompting**\n",
    "\n",
    "Definition:\n",
    "\n",
    "**Tool calling = the model selecting a tool and returning arguments for that tool in structured JSON.**\n",
    "\n",
    "A good tool-calling prompt:\n",
    "\n",
    "* Defines **all tools**\n",
    "* Specifies **when** each tool should be used\n",
    "* Requires **valid JSON**\n",
    "* Prevents hallucination\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ JSON Output**\n",
    "\n",
    "Definition:\n",
    "**JSON = a structured data format that machines can easily parse.**\n",
    "\n",
    "Agents need JSON for:\n",
    "\n",
    "* Routing tools\n",
    "* Returning structured data\n",
    "* Guaranteeing predictable behavior\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"action\": \"use_tool\",\n",
    "  \"tool\": \"web_search\",\n",
    "  \"parameters\": {\n",
    "    \"query\": \"weather in Mumbai\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **1.3 Reasoning Strategies**\n",
    "\n",
    "## **üîπ What Is Reasoning?**\n",
    "\n",
    "**Reasoning = how the model thinks through a problem before producing the answer.**\n",
    "\n",
    "Agents rely heavily on reasoning for:\n",
    "\n",
    "* Planning tasks\n",
    "* Fixing errors\n",
    "* Choosing the correct tool\n",
    "* Breaking down complex tasks\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Chain-of-Thought (CoT)**\n",
    "\n",
    "**CoT = step-by-step reasoning inside the model.**\n",
    "\n",
    "Example internal reasoning:\n",
    "\n",
    "```\n",
    "Step 1: Understand question\n",
    "Step 2: Identify needed tool\n",
    "Step 3: Call tool or answer\n",
    "```\n",
    "\n",
    "We keep this hidden from the user but used internally to produce more accurate results.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Tree-of-Thought (ToT)**\n",
    "\n",
    "**ToT = model explores multiple reasoning paths and selects the best one.**\n",
    "\n",
    "Useful for:\n",
    "\n",
    "* Planning agents\n",
    "* Coding agents\n",
    "* Research agents\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Self-Reflection Loops**\n",
    "\n",
    "**Self-reflection = the model evaluates its own previous steps and improves.**\n",
    "\n",
    "Example workflow:\n",
    "\n",
    "```\n",
    "1. Take action\n",
    "2. Check result\n",
    "3. Reflect on mistakes\n",
    "4. Try again with corrections\n",
    "```\n",
    "\n",
    "Used in:\n",
    "\n",
    "* Code fixer agents\n",
    "* Research loops\n",
    "* Multi-step planning systems\n",
    "\n",
    "---\n",
    "\n",
    "# ‚≠ê **Module 1 Summary (With Definitions)**\n",
    "\n",
    "Students now understand:\n",
    "\n",
    "‚úî What tokens are\n",
    "‚úî What context windows are\n",
    "‚úî What embeddings are\n",
    "‚úî How to choose the right model\n",
    "‚úî How prompts guide agent behavior\n",
    "‚úî Why JSON and tool schemas matter\n",
    "‚úî How models think using CoT, ToT & reflection\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
